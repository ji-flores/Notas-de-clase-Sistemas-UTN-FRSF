# MM - pt. III

### Atención al fallo de pagina

1. Notificación al SO.
2. Guardar los registros del usuario y estado del proceso.
3. Determinar que la interrupción fue un fallo de página
4. Verificar que la referencia a la página fue válida y determinar la posición de la página de disco.
5. Leer del disco a un marco libre.
6. Durante la espera asignar la CPU a algún otro usuario.
7. Interrupción del disco (E/S terminada)
8. Guardar los registros y el estado de proceso del otro usuario (si se llevó a cabo el paso 6)
9. Corregir la tabla de páginas y las demás tablas de modo que indiquen que la página ya esta en memoria
10. Esperar que la CPU se asigne otra vez a este proceso
11. Restaurar los registros de usuario, el estado de proceso y la nueva tabla de páginas y reanudar la ejecución interrumpida.

La paginación por demanda puede tener un efecto importante sobre el desempeño del sistema.

Es necesario calcular el tiempo de acceso efectivo.

Tiempo acceso a memoria tipico (AM) = [10,200] nanosegundos.

Si no hay fallos → Tiempo de acceso efectivo = Tiempo de acceso a memoria.

Si ocurre un fallo hay que leer del disco la página y luego acceder a la palabra deseada.

Entonces, si $p$ es la probabilidad de que ocurra un fallo, El tiempo efectivo de acceso ($t_{acceso\:efect.}$) es:

$$
t_{acceso\:efect.} = (1-p)\cdot t_{acceso\:a\:mem.} + p \cdot t_{fallo\:de \:pág.}
$$

![Untitled](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled.png)

![Esto ilustra que la performance depende muchisimo de *p.*](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%201.png)

Esto ilustra que la performance depende muchisimo de *p.*

## Algoritmos de reemplazo

### Evaluar un algoritmo de reemplazo.

Probarlo sobre una:

- **Cadena de referencia:** No es aleatoria. Se corre el proceso y se registra la sucesión de paginas que va accediendo.
- **Cantidad de marcos de página** asignados al proceso.

### Algoritmo optimo

Aquel que produce la menor cantidad de fallos de pagina. Es impracticable.

Cuando ocurre fallo página cierto conjunto de páginas se encuentran en memoria, y en la siguiente instrucción se hará referencia a una de estas páginas. Otras páginas no se usarán hasta 20200 o 1500 instrucciones más adelante

Cada página se va a etiquetar con el **número de instrucciones a ejecutar antes de hacer la primera  referencia a dicha página**.

1. Eliminar página con la máxima etiqueta.
2. Si una página no va a ser referenciada hasta dentro de X instrucciones y otra página se usará hasta dentro Y instrucciones, siendo X > Y: eliminar primero a la página que retrasa el fallo lo más posible (la de X).
3. Eliminar la página que más va a tardar en ser referenciada.

Es impracticable porque no puede saberse realmente cuantas instrucciones faltan.

Pero teniendo una cadena de referencia **si**.

***Idea:** Si una pagina se usó hace poco, tiene alta probabilidad de ser usada de vuelta en el futuro cercano (ser del working set).*

### No Recientemente Usado (NRU)

En tablas de pagina hay dos bits de estado: R (se activa si se hace referencia a la pagina) y M (se activa cuando se modifica la pagina). La CPU setea los bits R/M en cada referencia a memoria, y el SO los puede resetear a través de instrucciones de maquina.

1. Al iniciar el proceso, SO asigna 0 a R y M de todas las paginas.
2. En cada interrupción de reloj se limpia el bit R, (para distinguir paginas que no tengan referencia de las que si).
3. El SO divide las paginas en cuatro clases:
4. *Tabla:*

| Clase | R | M | Descripción |
| --- | --- | --- | --- |
| 0 | 0 | 0 | No referenciada, no modificada |
| 1 | 0 | 1 | No referenciada, pero modificada: significa que fue modificada hace mucho. |
| 2 | 1 | 0 | Referenciada, pero no modificada: Se la referenció pero no se escribió en ella. |
| 3 | 1 | 1 | Se la referencio recientemente y se la modificó. |
1. NRU elimina página de la primera clase no vacía con el número de clase más pequeño.

*Se prefiere la clase 0 a la 1, porque si se quita de la 1 se debe escribir en disco, lo cual es costoso.*

### First In, First Out (FIFO)

- El SO tiene una lista de todas las páginas en memoria, siendo la primera página la más antigua y la última la más reciente en ingresar a memoria.
- En un fallo de pagina se elimina la primera página y se añade la neuva al final de la lista.

Super ineficiente, nunca se tiene en cuenta el comportamiento del proceso.

### Segunda oportunidad

Es una modificación simple de FIFO, aprovechando el bit R.

*Cuando la página lleva al final de la cola, se decide:*

- *Si (R=0) ⇒ La página más antigua y no referenciada se reemplaza en forma inmediata.*
- *Si (R=1) ⇒ El bit R se pone en 0 y la página se coloca al final de la lista.*

Se implemente con una lista enlazada.

### Algoritmo del Reloj

Exactamente el mismo algoritmo que la segunda oportunidad, pero con una implementación más eficiente:

- Mantiene las páginas en una lista circular (reloj).
- Un puntero (aguja) apunta hacia la página más antigua.

Ocurre fallo de página:

- Si (R=0):
    - La página se retira de memoria
    - Se inserta nueva pagina en el lugar que ocupaba.
    - La aguja avanza una posición.
- Si (R=1):
    - Se cambia R=0.
    - La aguja avanza una posición.

### Anomalía de Belady

![Untitled](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%202.png)

*Como leerlo:*

- *La cantidad de filas es la cantidad de marcos asignados.*
- *La página que esta en la fila de más abajo es la más próxima a seleccionarse para salir.*
- *Una columna por página del string.*
- *Si se marca en rojo, significa que hubo un fallo de página.*

**La anomalía es:** Para un string de referencia dado, puede que si se aumentan la cantidad de marcos asignados, aumenten los fallos de página. Esto es inadmisible.

### Menos Recientemente Usado, o Least Recently Used (LRU)

**Consigna:** Mantener una lista ordenada de todas las paginas por el tiempo que paso desde la ultima vez que fueron referenciadas.

**Dificultad:** La lista debe actualizarse en cada referencia a memoria.

No es conveniente que se aplique para TdP, pero si lo es por ejemplo para memoria asociativa (porque es más chica)

### Implementación de LRU, 1

- Se implementa un contador de 64 bits por hardware, y cada pagina necesita una copia del valor del contador (no es necesario que se actualice el valor en cada pagina).
- Cada referencia a pagina hace que el contador crezca en 1.
- A la pagina que le guardas el contador, va a tener el contador mas grande.
- De esta manera, uno puede saber cual pagina fue usada mas recientemente, de acuerdo a la que tenga el contador mas grande.
- Reemplazas basicamente las que tiene el contador mas chico.

*Inconveniente:* ****Requiere memoria para almacenar el contador.

### Implementación de LRU, 2 (Pseudosolución por software)

### Maduración o Envejecimiento

Requiere almacenar un *registro* en la tabla de página:

- Comienza en 0.
- Periodicamente, se traslada el valor de R de cada pagina al registro.
    
    Se desplaza todo el contador a derecha (el valor de más a la derecha se “cae”), y en el bit de más a izquierda (mayor peso) se concatena el bit R.
    
- El numero binario almacenado en el registro en un momento dado ilustra cuan seguido es referenciada la página. El de menor valor es elegido para ser retirado de memoria. Si hay un empate, cualquiera.

### Marcos libres

- Muchos sistemas mantienen una reserva de marcos libres. Esto se realiza con un **demonio de paginación**, al llegar al minimo de marcos libres empieza a liberar marcos hasta llegar al tope.

### Reemplazo global/local

¿Que pasa si hay que cargar una nueva pagina de un proceso A? ¿Se retiran paginas solo del proceso A (local) o también de otros procesos (global)?

![a) Se quiere ingresar la página A6.
b) Se aplica reemplazo local.
c) Se aplica reemplazo global.](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%203.png)

a) Se quiere ingresar la página A6.
b) Se aplica reemplazo local.
c) Se aplica reemplazo global.

**Local:**

- **Ventaja:** El conjunto de páginas de un proceso que están en la memoria sólo depende del comportamiento de paginación de ese proceso.
- **Desventaja:** Podría obstaculizar ejecución de un proceso por no dejar que aproveche otras páginas de memoria de poco uso.

**Global:**

- **Ventaja:** Es flexible. Todos los marcos del sistema participan en el algoritmo de selección de la víctima. Cambian cuales paginas y la cantidad de páginas del working set.
- **Desventaja:** No se puede controlar la tasa de frecuencia de Fallos de Página de un proceso en particular.

El Reemplazo global generalmente aumenta el rendimiento de un sistema, y es el más usado.

En sistemas como AS/400 se combinan ambos métodos. Se separan los procesos en grupos (ej. Batch, Interactivos, Printer) Se asigna memoria a un grupo de procesos (Local), y todos los del grupo compiten por los marcos (Global).

### ¿Dónde en el disco se guardan las imágenes de los procesos?

| AREA DE SWAP (Linux) | ARCHIVO DE SWAP (Windows) |
| --- | --- |
| Tamaño Fijo: Limitado para crecimiento. | Tamaño Variable: No limitado para crecimiento.  |
| Tamaño Fijo: Puede desperdiciar espacio de disco.  | Tamaño Variable: Utiliza mejor el espacio de disco. |
| Mejor Rendimiento: no interactúa con Archivos. | Menor Rendimiento: interactúa con Archivos. |
| Mejor Rendimiento, el MM usa directamente el Driver de Disco. | Menor Rendimiento: El MM utiliza al FS quien gestiona el Disco usando el Driver de Disco. |

### Paginación por demanda vs Prepaginación

**Por demanda:**

- En general al cargar un proceso, el SO no carga ninguna pagina.
- Se referencia la primera página ⇒ Se genera un fallo y se carga la primera pagina.
- Y así hasta conseguir un working set.

Esta es la solución más usada.

**Prepaginación:**

- Al cargarse un proceso se le asignan aproximadamente tantos marcos como su Working Set.

### Programación con paginación

![Untitled](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%204.png)

![Untitled](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%205.png)

![Untitled](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%206.png)

### Predicción de tasa de fallos

![Untitled](MM%20-%20pt%20III%203281c582d5694e4387619af071059ac2/Untitled%207.png)

Solo se asignan 4 marcos, aunque no se este en memoria, se simula como se estuvieran y se los mantiene en la cola un tiempo más.

Se calcula la **distance string:** Es la fila en la que se encontraba la página en el paso anterior.

Puede usarse para precedir la cantidad de fallos para cualquier numero de marcos asignados. Notar que todas las columnas que tienen $\infin$ siempre generan un fallo porque significa que la página nunca fue referenciada.